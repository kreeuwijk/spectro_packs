presets:
  - name: "cni-disabled"
    displayName: "Disable"
    group: "CNI"
    remove: ["charts.istiod.cni"]
    add: |
      charts:
        istiod:
          cni:
            # Enable/disabe via preset to get all configurable options
            enabled: false

  - name: "cni-enabled"
    displayName: "Enable"
    group: "CNI"
    remove: ["charts.istiod.cni"]
    add: |
      charts:
        istiod:
          cni:
            # Enable/disabe via preset to get all configurable options
            enabled: true

            hub: ""
            tag: ""
            variant: ""
            image: install-cni
            pullPolicy: ""

            # Same as `global.logging.level`, but will override it if set
            logging:
              level: ""

            # Configuration file to insert istio-cni plugin configuration
            # by default this will be the first file found in the cni-conf-dir
            # Example
            # cniConfFileName: 10-calico.conflist

            # CNI-and-platform specific path defaults.
            # These may need to be set to platform-specific values, consult
            # overrides for your platform in `manifests/helm-profiles/platform-*.yaml`
            cniBinDir: /opt/cni/bin
            cniConfDir: /etc/cni/net.d
            cniConfFileName: ""
            cniNetnsDir: "/var/run/netns"

            # If Istio owned CNI config is enabled, defaults to 02-istio-cni.conflist
            istioOwnedCNIConfigFileName: "" 
            istioOwnedCNIConfig: false

            excludeNamespaces:
              - kube-system

            # Allows user to set custom affinity for the DaemonSet
            affinity: {}

            # Custom annotations on pod level, if you need them
            podAnnotations: {}

            # Deploy the config files as plugin chain (value "true") or as standalone files in the conf dir (value "false")?
            # Some k8s flavors (e.g. OpenShift) do not support the chain approach, set to false if this is the case
            chained: true

            # Custom configuration happens based on the CNI provider.
            # Possible values: "default", "multus"
            provider: "default"

            # Configure ambient settings
            ambient:
              # If enabled, ambient redirection will be enabled
              enabled: false
              # If ambient is enabled, this selector will be used to identify the ambient-enabled pods
              enablementSelectors: 
              - podSelector:
                  matchLabels: {istio.io/dataplane-mode: ambient}
              - podSelector:
                  matchExpressions:
                  - { key: istio.io/dataplane-mode, operator: NotIn, values: [none] }
                namespaceSelector:
                  matchLabels: {istio.io/dataplane-mode: ambient}
              # Set ambient config dir path: defaults to /etc/ambient-config
              configDir: ""
              # If enabled, and ambient is enabled, DNS redirection will be enabled
              dnsCapture: true
              # If enabled, and ambient is enabled, enables ipv6 support
              ipv6: true
              # If enabled, and ambient is enabled, the CNI agent will reconcile incompatible iptables rules and chains at startup.
              # This will eventually be enabled by default
              reconcileIptablesOnStartup: false
              # If enabled, and ambient is enabled, the CNI agent will always share the network namespace of the host node it is running on
              shareHostNetworkNamespace: false


            repair:
              enabled: true
              hub: ""
              tag: ""

              # Repair controller has 3 modes. Pick which one meets your use cases. Note only one may be used.
              # This defines the action the controller will take when a pod is detected as broken.

              # labelPods will label all pods with <brokenPodLabelKey>=<brokenPodLabelValue>.
              # This is only capable of identifying broken pods; the user is responsible for fixing them (generally, by deleting them).
              # Note this gives the DaemonSet a relatively high privilege, as modifying pod metadata/status can have wider impacts.
              labelPods: false
              # deletePods will delete any broken pod. These will then be rescheduled, hopefully onto a node that is fully ready.
              # Note this gives the DaemonSet a relatively high privilege, as it can delete any Pod.
              deletePods: false
              # repairPods will dynamically repair any broken pod by setting up the pod networking configuration even after it has started.
              # Note the pod will be crashlooping, so this may take a few minutes to become fully functional based on when the retry occurs.
              # This requires no RBAC privilege, but does require `securityContext.privileged/CAP_SYS_ADMIN`.
              repairPods: true

              initContainerName: "istio-validation"

              brokenPodLabelKey: "cni.istio.io/uninitialized"
              brokenPodLabelValue: "true"

            # Set to `type: RuntimeDefault` to use the default profile if available.
            seccompProfile: {}

            # SELinux options to set in the istio-cni-node pods. You may need to set this to `type: spc_t` for some platforms.
            seLinuxOptions: {}

            resources:
              requests:
                cpu: 100m
                memory: 100Mi

            resourceQuotas:
              enabled: false
              pods: 5000

            tolerations:
              # Make sure istio-cni-node gets scheduled on all nodes.
              - effect: NoSchedule
                operator: Exists
              # Mark the pod as a critical add-on for rescheduling.
              - key: CriticalAddonsOnly
                operator: Exists
              - effect: NoExecute
                operator: Exists

            # K8s DaemonSet update strategy.
            # https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/daemon-set-v1/#DaemonSetSpec).
            updateStrategy:
              type: RollingUpdate
              rollingUpdate:
                maxUnavailable: 1

            # Revision is set as 'version' label and part of the resource names when installing multiple control planes.
            revision: ""

            # For Helm compatibility.
            ownerName: ""

            global:
              # Default hub for Istio images.
              # Releases are published to docker hub under 'istio' project.
              # Dev builds from prow are on gcr.io
              hub: docker.io/istio

              # Default tag for Istio images.
              tag: 1.27.0

              # Variant of the image to use.
              # Currently supported are: [debug, distroless]
              variant: ""

              # Specify image pull policy if default behavior isn't desired.
              # Default behavior: latest images will be Always else IfNotPresent.
              imagePullPolicy: ""

              # change cni scope level to control logging out of istio-cni-node DaemonSet
              logging:
                level: info

              logAsJson: false

              # ImagePullSecrets for all ServiceAccount, list of secrets in the same namespace
              # to use for pulling any images in pods that reference this ServiceAccount.
              # For components that don't use ServiceAccounts (i.e. grafana, servicegraph, tracing)
              # ImagePullSecrets will be added to the corresponding Deployment(StatefulSet) objects.
              # Must be set for any cluster configured with private docker registry.
              imagePullSecrets: []
              # - private-registry-key

              # Default resources allocated
              defaultResources:
                requests:
                  cpu: 100m
                  memory: 100Mi

              # In order to use native nftable rules instead of iptable rules, set this flag to true.
              nativeNftables: false

            # A `key: value` mapping of environment variables to add to the pod
            env: {}


  - name: "gateway-disabled"
    displayName: "Disable"
    group: "Gateway"
    remove: ["charts.istiod.gateway"]
    add: |
      charts:
        istiod:
          gateway:
            # Enable/disabe via preset to get all configurable options
            enabled: false

  - name: "gateway-enabled"
    displayName: "Enable"
    group: "Gateway"
    remove: ["charts.istiod.gateway"]
    add: |
      charts:
        istiod:
          gateway:
            # Enable/disabe via preset to get all configurable options
            enabled: true

            # Name allows overriding the release name. Generally this should not be set
            name: ""
            # revision declares which revision this gateway is a part of
            revision: ""

            # Controls the spec.replicas setting for the Gateway deployment if set.
            # Otherwise defaults to Kubernetes Deployment default (1).
            replicaCount:

            kind: Deployment

            rbac:
              # If enabled, roles will be created to enable accessing certificates from Gateways. This is not needed
              # when using http://gateway-api.org/.
              enabled: true

            serviceAccount:
              # If set, a service account will be created. Otherwise, the default is used
              create: true
              # Annotations to add to the service account
              annotations: {}
              # The name of the service account to use.
              # If not set, the release name is used
              name: ""

            podAnnotations:
              prometheus.io/port: "15020"
              prometheus.io/scrape: "true"
              prometheus.io/path: "/stats/prometheus"
              inject.istio.io/templates: "gateway"
              sidecar.istio.io/inject: "true"

            # Define the security context for the pod.
            # If unset, this will be automatically set to the minimum privileges required to bind to port 80 and 443.
            # On Kubernetes 1.22+, this only requires the `net.ipv4.ip_unprivileged_port_start` sysctl.
            securityContext: {}
            containerSecurityContext: {}

            service:
              # Type of service. Set to "None" to disable the service entirely
              type: LoadBalancer
              ports:
              - name: status-port
                port: 15021
                protocol: TCP
                targetPort: 15021
              - name: http2
                port: 80
                protocol: TCP
                targetPort: 80
              - name: https
                port: 443
                protocol: TCP
                targetPort: 443
              annotations: {}
              loadBalancerIP: ""
              loadBalancerSourceRanges: []
              externalTrafficPolicy: ""
              externalIPs: []
              ipFamilyPolicy: ""
              ipFamilies: []
              ## Whether to automatically allocate NodePorts (only for LoadBalancers).
              # allocateLoadBalancerNodePorts: false
              ## Set LoadBalancer class (only for LoadBalancers).
              # loadBalancerClass: ""

            resources:
              requests:
                cpu: 100m
                memory: 128Mi
              limits:
                cpu: 2000m
                memory: 1024Mi

            autoscaling:
              enabled: true
              minReplicas: 1
              maxReplicas: 5
              targetCPUUtilizationPercentage: 80
              targetMemoryUtilizationPercentage: {}
              autoscaleBehavior: {}

            # Pod environment variables
            env: {}

            # Use envVarFrom to define full environment variable entries with complex sources,
            # such as valueFrom.secretKeyRef, valueFrom.configMapKeyRef. Each item must include a `name` and `valueFrom`.
            #
            # Example:
            # envVarFrom:
            #   - name: EXAMPLE_SECRET
            #     valueFrom:
            #       secretKeyRef:
            #         name: example-name
            #         key: example-key
            envVarFrom: []

            # Deployment Update strategy
            strategy: {}
            
            # Sets the Deployment minReadySeconds value
            minReadySeconds:
            
            # Optionally configure a custom readinessProbe. By default the control plane
            # automatically injects the readinessProbe. If you wish to override that
            # behavior, you may define your own readinessProbe here.
            readinessProbe: {}

            # Labels to apply to all resources
            labels:
              # By default, don't enroll gateways into the ambient dataplane
              "istio.io/dataplane-mode": none

            # Annotations to apply to all resources
            annotations: {}

            nodeSelector: {}

            tolerations: []

            topologySpreadConstraints: []

            affinity: {}

            # If specified, the gateway will act as a network gateway for the given network.
            networkGateway: ""

            # Specify image pull policy if default behavior isn't desired.
            # Default behavior: latest images will be Always else IfNotPresent
            imagePullPolicy: ""

            imagePullSecrets: []

            # This value is used to configure a Kubernetes PodDisruptionBudget for the gateway.
            #
            # By default, the `podDisruptionBudget` is disabled (set to `{}`),
            # which means that no PodDisruptionBudget resource will be created.
            #
            # To enable the PodDisruptionBudget, configure it by specifying the
            # `minAvailable` or `maxUnavailable`. For example, to set the
            # minimum number of available replicas to 1, you can update this value as follows:
            #
            # podDisruptionBudget:
            #   minAvailable: 1
            #
            # Or, to allow a maximum of 1 unavailable replica, you can set:
            #
            # podDisruptionBudget:
            #   maxUnavailable: 1
            #
            # You can also specify the `unhealthyPodEvictionPolicy` field, and the valid values are `IfHealthyBudget` and `AlwaysAllow`.
            # For example, to set the `unhealthyPodEvictionPolicy` to `AlwaysAllow`, you can update this value as follows:
            #
            # podDisruptionBudget:
            #   minAvailable: 1
            #   unhealthyPodEvictionPolicy: AlwaysAllow
            #
            # To disable the PodDisruptionBudget, you can leave it as an empty object `{}`:
            #
            # podDisruptionBudget: {}
            #
            podDisruptionBudget: {}

            # Sets the per-pod terminationGracePeriodSeconds setting.
            terminationGracePeriodSeconds: 30

            # A list of `Volumes` added into the Gateway Pods. See
            # https://kubernetes.io/docs/concepts/storage/volumes/.
            volumes: []

            # A list of `VolumeMounts` added into the Gateway Pods. See
            # https://kubernetes.io/docs/concepts/storage/volumes/.
            volumeMounts: []

            # Inject initContainers into the Gateway Pods.
            initContainers: []

            # Inject additional containers into the Gateway Pods.
            additionalContainers: []

            # Configure this to a higher priority class in order to make sure your Istio gateway pods
            # will not be killed because of low priority class.
            # Refer to https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass
            # for more detail.
            priorityClassName: ""

            # Configure the lifecycle hooks for the gateway. See
            # https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/.
            lifecycle: {}

  - name: "kiali-disabled"
    displayName: "Disable"
    group: "Kiali Dashboard"
    remove: ["charts.kiali-server"]
    add: |
      charts:
        kiali-server:
          enabled: false

  - name: "kiali-enabled"
    displayName: "Enable"
    group: "Kiali Dashboard"
    remove: []
    add: |
      charts:
        kiali-server:
          enabled: true
          fullnameOverride: "kiali"

          # This is required for "openshift" auth strategy.
          # You have to know ahead of time what your Route URL will be because
          # right now the helm chart can't figure this out at runtime (it would
          # need to wait for the Kiali Route to be deployed and for OpenShift
          # to start it up). If someone knows how to update this helm chart to
          # do this, a PR would be welcome.
          kiali_route_url: ""

          #
          # Settings that mimic the Kiali CR which are placed in the ConfigMap.
          # Note that only those values used by the Helm Chart will be here.
          #

          additional_display_details:
          - annotation: kiali.io/api-spec
            icon_annotation: kiali.io/api-type
            title: API Documentation

          istio_namespace: "" # default is where Kiali is installed

          auth:
            openid: {}
            openshift: {}
            strategy: ""

          clustering:
            autodetect_secrets:
              enabled: true
              label: "kiali.io/multiCluster=true"
            clusters: []

          deployment:
            additional_service_yaml: {}
            affinity:
              node: {}
              pod: {}
              pod_anti: {}
            # The Kiali server helm chart only supports cluster-wide access; setting cluster_wide_access to false is not supported.
            # For more control over what the Kial Service Account can see, use the Kiali Operator.
            cluster_wide_access: true
            configmap_annotations: {}
            custom_envs: []
            custom_secrets: []
            dns:
              config: {}
              policy: ""
            host_aliases: []
            hpa:
              api_version: "autoscaling/v2"
              spec: {}
            image_digest: "" # use "sha256" if image_version is a sha256 hash (do NOT prefix this value with a "@")
            image_name: us-docker.pkg.dev/palette-images/packs/istio/1.26.0/kiali
            image_pull_policy: "Always"
            image_pull_secrets: []
            image_version: v2.11.0 # version like "v1.39" (see: https://quay.io/repository/kiali/kiali?tab=tags) or a digest hash
            ingress:
              additional_labels: {}
              class_name: "nginx"
              #enabled:
              override_yaml:
                metadata: {}
            instance_name: "kiali"
            logger:
              log_format: "text"
              log_level: "info"
              time_field_format: "2006-01-02T15:04:05Z07:00"
              sampler_rate: "1"
            node_selector: {}
            pod_annotations: {}
            pod_labels: {}
            priority_class_name: ""
            remote_cluster_resources_only: false
            # if deployment.hpa is defined, this replicas setting will be ignored
            replicas: 1
            resources:
              requests:
                cpu: "10m"
                memory: "64Mi"
              limits:
                memory: "1Gi"
            secret_name: "kiali"
            security_context: {}
            service_annotations: {}
            service_type: ""
            tolerations: []
            topology_spread_constraints: []
            version_label: v2.11.0 # v1.39 # v1.39.0 # see: https://quay.io/repository/kiali/kiali?tab=tags
            view_only_mode: false

          external_services:
            prometheus:
              url: "http://prometheus.istio-system:9090/"
            custom_dashboards:
              enabled: true
            istio:
              root_namespace: ""

          identity: {}
            #cert_file:
            #private_key_file:

          kiali_feature_flags:
            disabled_features: []
            validations:
              ignore: ["KIA1301"]

          login_token:
            signing_key: ""

          server:
            port: 20001
            #node_port:
            observability:
              metrics:
                enabled: true
                port: 9090
            web_root: ""
